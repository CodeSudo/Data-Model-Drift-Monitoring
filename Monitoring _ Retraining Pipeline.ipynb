{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e0f6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install alibi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5acde951",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install alibi-detect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb2f7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "!pip install snowflake-connector-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c37296",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "!pip install snowflake-sqlalchemy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dacb36a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2b4cfcfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 200)\n",
    "\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "import pickle \n",
    "\n",
    "import sklearn\n",
    "from sklearn import metrics\n",
    "\n",
    "import alibi \n",
    "from alibi_detect.cd import ChiSquareDrift, TabularDrift\n",
    "from alibi_detect.saving import save_detector, load_detector\n",
    "\n",
    "import sqlalchemy\n",
    "import snowflake.connector\n",
    "from sqlalchemy import create_engine\n",
    "from snowflake.sqlalchemy import *\n",
    "\n",
    "import xgboost\n",
    "from datetime import datetime, timedelta\n",
    "import time  \n",
    "import pytz    \n",
    "tz_NY = pytz.timezone('Asia/Kolkata')\n",
    "\n",
    "import snowflake_creds\n",
    "import LOS_Preprocessing\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d1ddc6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the connection engine (way 1)\n",
    "engine = create_engine(URL(\n",
    "        account=\"cr21746.ap-south-1\",\n",
    "        user= snowflake_creds.USER_NAME,\n",
    "        password= snowflake_creds.PASSWORD,\n",
    "        role=\"ACCOUNTADMIN\",\n",
    "        warehouse=\"COMPUTE_WH\",\n",
    "        database=\"HEALTHDB\",\n",
    "        schema=\"HEALTHSCHEMA\"\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5167d828",
   "metadata": {},
   "source": [
    "## Data Drift Detector Script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6871f0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_monitoring_batch_query(a):\n",
    "    query = f\"\"\"\n",
    "\n",
    "        SELECT CASE_ID,\n",
    "               COALESCE(HOSPITAL_CODE,0) AS HOSPITAL_CODE,\n",
    "               COALESCE(HOSPITAL_TYPE_CODE,'None') AS HOSPITAL_TYPE_CODE,\n",
    "               COALESCE(CITY_CODE_HOSPITAL,0) AS CITY_CODE_HOSPITAL,\n",
    "               COALESCE(HOSPITAL_REGION_CODE,'None') AS HOSPITAL_REGION_CODE,\n",
    "               COALESCE(AVAILABLE_EXTRA_ROOMS_IN_HOSPITAL_X,0) AS AVAILABLE_EXTRA_ROOMS_IN_HOSPITAL,\n",
    "               COALESCE(DEPARTMENT,'None') AS DEPARTMENT,\n",
    "               COALESCE(WARD_TYPE,'None') AS WARD_TYPE,\n",
    "               COALESCE(WARD_FACILITY_CODE,'None') AS WARD_FACILITY_CODE,\n",
    "               COALESCE(BED_GRADE,0) AS BED_GRADE,\n",
    "               PATIENTID,\n",
    "               COALESCE(CITY_CODE_PATIENT,0) AS CITY_CODE_PATIENT,\n",
    "               COALESCE(TYPE_OF_ADMISSION,'None') AS TYPE_OF_ADMISSION,\n",
    "               COALESCE(SEVERITY_OF_ILLNESS,'Minor') AS SEVERITY_OF_ILLNESS,\n",
    "               COALESCE(VISITORS_WITH_PATIENT_X,0) AS VISITORS_WITH_PATIENT,\n",
    "               COALESCE(AGE,'None') AS AGE,\n",
    "               COALESCE(ADMISSION_DEPOSIT_X,0) AS ADMISSION_DEPOSIT,\n",
    "               ADMISSION_DATE,\n",
    "               DISCHARGE_DATE\n",
    "\n",
    "            FROM HEALTHDB.HEALTHSCHEMA.TEMP_LOS_PREDICTION_MODEL_LOGGING_TABLE_HARI\n",
    "            WHERE ADMISSION_DATE >= CURRENT_DATE-144+{a*7} AND ADMISSION_DATE < CURRENT_DATE-144+{(a+1)*7}        \n",
    "\n",
    "        \"\"\"\n",
    "    return query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1b0b8754",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_monitoring(batch_id):\n",
    "    # Loading the train data\n",
    "    with engine.connect() as conn:\n",
    "        batch_df = pd.DataFrame(pd.read_sql(data_monitoring_batch_query(batch_id),conn))\n",
    "        batch_df.columns = [col.upper() for col in batch_df.columns.tolist()]\n",
    "    \n",
    "    # Getting the numerical and categorical columns for creating the datadrift object\n",
    "    num_columns = ['AVAILABLE_EXTRA_ROOMS_IN_HOSPITAL','VISITORS_WITH_PATIENT','ADMISSION_DEPOSIT']\n",
    "    id_columns = ['CASE_ID','PATIENTID','ADMISSION_DATE','DISCHARGE_DATE']\n",
    "    cat_columns = [col for col in batch_df.columns.tolist() if col not in num_columns+id_columns]\n",
    "    \n",
    "    # Getting the final prepared data\n",
    "    batch_final = batch_df[num_columns + cat_columns]\n",
    "    \n",
    "    # Loading the Trained data drift detector\n",
    "    with open('Trained_Drift_Detector.pkl','rb') as F:\n",
    "        trained_drift_model = pickle.load(F)    \n",
    "    \n",
    "    # Checking for drift\n",
    "    # If you are interested in individual feature-wise drift, this is also possible:\n",
    "    fpreds = trained_drift_model.predict(batch_final.values, drift_type='feature')\n",
    "    \n",
    "    log_df = pd.DataFrame()\n",
    "    log_df['Time Period'] = ([str(batch_df['ADMISSION_DATE'].min()) + ' to ' + \n",
    "                              str(batch_df['ADMISSION_DATE'].max())]\n",
    "                              * len(batch_final.columns.tolist())\n",
    "                            )\n",
    "    log_df['Total Records'] = batch_df.shape[0]\n",
    "    log_df['Features'] = batch_final.columns.tolist()\n",
    "    log_df['Is Drift'] = fpreds['data']['is_drift']\n",
    "    log_df['Stat Test'] = log_df['Features'].apply(lambda x: 'Chi2' if x in cat_columns else 'K-S')\n",
    "    log_df['Stats Value'] = np.round(fpreds['data']['distance'])\n",
    "    log_df['P-value'] = np.round(fpreds['data']['p_val'])\n",
    "    \n",
    "    return log_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2a9d4cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_log_df = data_monitoring(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "867dfc7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time Period</th>\n",
       "      <th>Total Records</th>\n",
       "      <th>Features</th>\n",
       "      <th>Is Drift</th>\n",
       "      <th>Stat Test</th>\n",
       "      <th>Stats Value</th>\n",
       "      <th>P-value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-12-19 to 2022-12-25</td>\n",
       "      <td>16689</td>\n",
       "      <td>AVAILABLE_EXTRA_ROOMS_IN_HOSPITAL</td>\n",
       "      <td>1</td>\n",
       "      <td>K-S</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-12-19 to 2022-12-25</td>\n",
       "      <td>16689</td>\n",
       "      <td>VISITORS_WITH_PATIENT</td>\n",
       "      <td>1</td>\n",
       "      <td>K-S</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-12-19 to 2022-12-25</td>\n",
       "      <td>16689</td>\n",
       "      <td>ADMISSION_DEPOSIT</td>\n",
       "      <td>1</td>\n",
       "      <td>K-S</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-12-19 to 2022-12-25</td>\n",
       "      <td>16689</td>\n",
       "      <td>HOSPITAL_CODE</td>\n",
       "      <td>1</td>\n",
       "      <td>Chi2</td>\n",
       "      <td>124.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-12-19 to 2022-12-25</td>\n",
       "      <td>16689</td>\n",
       "      <td>HOSPITAL_TYPE_CODE</td>\n",
       "      <td>1</td>\n",
       "      <td>Chi2</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2022-12-19 to 2022-12-25</td>\n",
       "      <td>16689</td>\n",
       "      <td>CITY_CODE_HOSPITAL</td>\n",
       "      <td>1</td>\n",
       "      <td>Chi2</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2022-12-19 to 2022-12-25</td>\n",
       "      <td>16689</td>\n",
       "      <td>HOSPITAL_REGION_CODE</td>\n",
       "      <td>1</td>\n",
       "      <td>Chi2</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2022-12-19 to 2022-12-25</td>\n",
       "      <td>16689</td>\n",
       "      <td>DEPARTMENT</td>\n",
       "      <td>1</td>\n",
       "      <td>Chi2</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2022-12-19 to 2022-12-25</td>\n",
       "      <td>16689</td>\n",
       "      <td>WARD_TYPE</td>\n",
       "      <td>1</td>\n",
       "      <td>Chi2</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2022-12-19 to 2022-12-25</td>\n",
       "      <td>16689</td>\n",
       "      <td>WARD_FACILITY_CODE</td>\n",
       "      <td>1</td>\n",
       "      <td>Chi2</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2022-12-19 to 2022-12-25</td>\n",
       "      <td>16689</td>\n",
       "      <td>BED_GRADE</td>\n",
       "      <td>1</td>\n",
       "      <td>Chi2</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2022-12-19 to 2022-12-25</td>\n",
       "      <td>16689</td>\n",
       "      <td>CITY_CODE_PATIENT</td>\n",
       "      <td>1</td>\n",
       "      <td>Chi2</td>\n",
       "      <td>233.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2022-12-19 to 2022-12-25</td>\n",
       "      <td>16689</td>\n",
       "      <td>TYPE_OF_ADMISSION</td>\n",
       "      <td>1</td>\n",
       "      <td>Chi2</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2022-12-19 to 2022-12-25</td>\n",
       "      <td>16689</td>\n",
       "      <td>SEVERITY_OF_ILLNESS</td>\n",
       "      <td>1</td>\n",
       "      <td>Chi2</td>\n",
       "      <td>59.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2022-12-19 to 2022-12-25</td>\n",
       "      <td>16689</td>\n",
       "      <td>AGE</td>\n",
       "      <td>1</td>\n",
       "      <td>Chi2</td>\n",
       "      <td>188.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Time Period  Total Records  \\\n",
       "0   2022-12-19 to 2022-12-25          16689   \n",
       "1   2022-12-19 to 2022-12-25          16689   \n",
       "2   2022-12-19 to 2022-12-25          16689   \n",
       "3   2022-12-19 to 2022-12-25          16689   \n",
       "4   2022-12-19 to 2022-12-25          16689   \n",
       "5   2022-12-19 to 2022-12-25          16689   \n",
       "6   2022-12-19 to 2022-12-25          16689   \n",
       "7   2022-12-19 to 2022-12-25          16689   \n",
       "8   2022-12-19 to 2022-12-25          16689   \n",
       "9   2022-12-19 to 2022-12-25          16689   \n",
       "10  2022-12-19 to 2022-12-25          16689   \n",
       "11  2022-12-19 to 2022-12-25          16689   \n",
       "12  2022-12-19 to 2022-12-25          16689   \n",
       "13  2022-12-19 to 2022-12-25          16689   \n",
       "14  2022-12-19 to 2022-12-25          16689   \n",
       "\n",
       "                             Features  Is Drift Stat Test  Stats Value  \\\n",
       "0   AVAILABLE_EXTRA_ROOMS_IN_HOSPITAL         1       K-S          0.0   \n",
       "1               VISITORS_WITH_PATIENT         1       K-S          0.0   \n",
       "2                   ADMISSION_DEPOSIT         1       K-S          0.0   \n",
       "3                       HOSPITAL_CODE         1      Chi2        124.0   \n",
       "4                  HOSPITAL_TYPE_CODE         1      Chi2         18.0   \n",
       "5                  CITY_CODE_HOSPITAL         1      Chi2         37.0   \n",
       "6                HOSPITAL_REGION_CODE         1      Chi2          8.0   \n",
       "7                          DEPARTMENT         1      Chi2         21.0   \n",
       "8                           WARD_TYPE         1      Chi2         45.0   \n",
       "9                  WARD_FACILITY_CODE         1      Chi2         11.0   \n",
       "10                          BED_GRADE         1      Chi2         40.0   \n",
       "11                  CITY_CODE_PATIENT         1      Chi2        233.0   \n",
       "12                  TYPE_OF_ADMISSION         1      Chi2         42.0   \n",
       "13                SEVERITY_OF_ILLNESS         1      Chi2         59.0   \n",
       "14                                AGE         1      Chi2        188.0   \n",
       "\n",
       "    P-value  \n",
       "0       0.0  \n",
       "1       0.0  \n",
       "2       0.0  \n",
       "3       0.0  \n",
       "4       0.0  \n",
       "5       0.0  \n",
       "6       0.0  \n",
       "7       0.0  \n",
       "8       0.0  \n",
       "9       0.0  \n",
       "10      0.0  \n",
       "11      0.0  \n",
       "12      0.0  \n",
       "13      0.0  \n",
       "14      0.0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_log_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6972d61d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "53d24df3",
   "metadata": {},
   "source": [
    "## Model Drift Detector Script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a8d09268",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to check model drift\n",
    "def check_model_drift(ref_metric_dict,cur_metric_dict,type='classification',tol=0.1):\n",
    "    if type == 'classification':\n",
    "        precision_change = abs((cur_metric_dict['Precision']-ref_metric_dict['Precision'])/ref_metric_dict['Precision'])\n",
    "        recall_change = abs((cur_metric_dict['Recall']-ref_metric_dict['Recall'])/ref_metric_dict['Recall'])\n",
    "        roc_auc_change = abs((cur_metric_dict['Roc-Auc']-ref_metric_dict['Roc-Auc'])/ref_metric_dict['Roc-Auc'])\n",
    "\n",
    "        counter = 0\n",
    "        for i in [precision_change,recall_change,roc_auc_change]:\n",
    "            if i > tol:\n",
    "                counter += 1\n",
    "\n",
    "        if counter > 0:\n",
    "            print(\"ALERT! There is a model drift.\")\n",
    "            print(\"Change in Precision: \"+ str(np.round(100*precision_change,2))+\"%\")\n",
    "            print(\"Change in Recall: \"+ str(np.round(100*recall_change,2))+\"%\")\n",
    "            print(\"Change in Roc-Auc: \"+ str(np.round(100*roc_auc_change,2))+\"%\")\n",
    "            return 1\n",
    "        else:\n",
    "            print(\"There is no model drift.\")\n",
    "            return 0\n",
    "\n",
    "    elif type == 'regression':\n",
    "        rmse_change = abs((cur_metric_dict['RMSE']-ref_metric_dict['RMSE'])/ref_metric_dict['RMSE'])\n",
    "        mae_change = abs((cur_metric_dict['MAE']-ref_metric_dict['MAE'])/ref_metric_dict['MAE'])\n",
    "        \n",
    "        counter = 0\n",
    "        for i in [rmse_change,mae_change]:\n",
    "            if i > tol:\n",
    "                counter += 1\n",
    "\n",
    "        if counter > 0:\n",
    "            print(\"ALERT! There is a model drift.\")\n",
    "            RMSE_CHANGE = np.round(100*rmse_change,2)\n",
    "            MAE_CHANGE = np.round(100*mae_change,2)\n",
    "            print(\"Change in RMSE: \"+ str(np.round(100*rmse_change,2))+\"%\")\n",
    "            print(\"Change in MAE: \"+ str(np.round(100*mae_change,2))+\"%\")\n",
    "            return 1, RMSE_CHANGE, MAE_CHANGE\n",
    "        else:\n",
    "            print(\"There is no model drift.\")\n",
    "            RMSE_CHANGE = 'NONE'\n",
    "            MAE_CHANGE = 'NONE'\n",
    "            return 0, RMSE_CHANGE, MAE_CHANGE\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f3965b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_monitoring_batch_query(a):\n",
    "    query_sim = f\"\"\"\n",
    "\n",
    "        SELECT *\n",
    "        FROM TEMP_LOS_PREDICTION_MODEL_LOGGING_TABLE_HARI\n",
    "        WHERE ADMISSION_DATE >= CURRENT_DATE-144+{a*7} AND ADMISSION_DATE < CURRENT_DATE-144+{(a+1)*7}\n",
    "        \n",
    "    \"\"\"\n",
    "    return query_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ff3fd1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_monitoring(batch_id):\n",
    "    # Loading the train data\n",
    "    with engine.connect() as conn:\n",
    "        batch_df = pd.DataFrame(pd.read_sql(model_monitoring_batch_query(batch_id),conn))\n",
    "        batch_df.columns = [col.upper() for col in batch_df.columns.tolist()]\n",
    "    \n",
    "#     print(batch_df.shape)\n",
    "    \n",
    "    # Creating the current performance dict (from scoring)\n",
    "    actual = batch_df['LOS_X']\n",
    "    predicted = batch_df['PREDICTED_LOS']\n",
    "\n",
    "    rmse = np.sqrt(metrics.mean_squared_error(actual,predicted))\n",
    "    mae = np.sqrt(metrics.mean_absolute_error(actual,predicted))\n",
    "#     print(\"RMSE: \", rmse)\n",
    "#     print(\"MAE: \", mae)\n",
    "\n",
    "    scoring_ref_metrics = {}\n",
    "    scoring_ref_metrics['RMSE'] = rmse\n",
    "    scoring_ref_metrics['MAE'] = mae #+ 0.2*mae\n",
    "#     print(scoring_ref_metrics)\n",
    "    \n",
    "    \n",
    "    # Loading the reference performance dict (from training)\n",
    "    with open('MODEL_XGB_PERFM_METRICS.pkl', 'rb') as F:\n",
    "        model_ref_metric = pickle.load(F)\n",
    "        \n",
    "#     print(model_ref_metric)\n",
    "    \n",
    "    # Check for model drift\n",
    "    model_drift, RMSE_CHANGE, MAE_CHANGE = check_model_drift(model_ref_metric,scoring_ref_metrics,type='regression',tol=0.1)\n",
    "    \n",
    "    # Log values\n",
    "    log = {}\n",
    "    log['Time Period'] = str(batch_df['ADMISSION_DATE'].min()) + ' to ' + str(batch_df['ADMISSION_DATE'].max())\n",
    "    log['Total Records'] = batch_df.shape[0]\n",
    "    log['Scoring Metrics'] = scoring_ref_metrics\n",
    "    log['Training Metrics'] = model_ref_metric\n",
    "    log['Model Drift IND'] = model_drift\n",
    "    log['RMSE Change'] = RMSE_CHANGE\n",
    "    log['MAE Change'] = MAE_CHANGE\n",
    "    \n",
    "    return log\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6f3d012b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is no model drift.\n"
     ]
    }
   ],
   "source": [
    "model_log_dict = model_monitoring(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c64607b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Time Period': '2022-12-19 to 2022-12-25',\n",
       " 'Total Records': 16689,\n",
       " 'Scoring Metrics': {'RMSE': 14.879287386202929, 'MAE': 3.298999279937221},\n",
       " 'Training Metrics': {'RMSE': 13.607345304032433, 'MAE': 3.1702232476032353},\n",
       " 'Model Drift IND': 0,\n",
       " 'RMSE Change': 'NONE',\n",
       " 'MAE Change': 'NONE'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_log_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da2a4c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "45e7bbaa",
   "metadata": {},
   "source": [
    "# Retraining Helper Functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4ccef3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_n_create_model_features(df,feat_list):\n",
    "    test = pd.DataFrame()\n",
    "    for col in feat_list:\n",
    "        if col in df.columns.tolist():\n",
    "            test[col] = df[col]\n",
    "        else:\n",
    "            test[col] = 0\n",
    "    \n",
    "    return test\n",
    "\n",
    "def feature_selection(df):\n",
    "    # Creating X and Y\n",
    "    x_train = df.drop('LOS',axis=1)\n",
    "    y_train = df[['LOS']]\n",
    "    \n",
    "    # Decision Tree\n",
    "    from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "    dtree = DecisionTreeRegressor()\n",
    "    dtree.fit(x_train,y_train)\n",
    "    # Feature Importance\n",
    "    feat_imp = (pd.DataFrame(zip(x_train.columns,dtree.feature_importances_),columns=['feature','imp'])\n",
    "                .sort_values(by='imp',ascending=False))\n",
    "    final_features_dtree = feat_imp[feat_imp['imp']>=0.01]['feature'].values.tolist()\n",
    "    \n",
    "    # XGBoost\n",
    "    import xgboost as xgb\n",
    "\n",
    "    xgb_ = xgb.XGBRegressor()\n",
    "    xgb_.fit(x_train,y_train)\n",
    "    # Feature Importance\n",
    "    feat_imp = (pd.DataFrame(zip(x_train.columns,xgb_.feature_importances_),columns=['feature','imp'])\n",
    "                .sort_values(by='imp',ascending=False))\n",
    "    final_features_xgb = feat_imp[feat_imp['imp']>=0.01]['feature'].values.tolist()\n",
    "    \n",
    "    model_features =  list(set(final_features_dtree).union(set(final_features_xgb)))\n",
    "    print(\"Final Features from both Dtree & XGB: \"+str(len(model_features)))\n",
    "    \n",
    "    import pickle\n",
    "\n",
    "    final_feats_list = model_features+['LOS']\n",
    "\n",
    "    with open('./Retraining Artifacts/MODEL_FEATS.pkl','wb') as F:\n",
    "        pickle.dump(final_feats_list,F)\n",
    "    \n",
    "    return final_feats_list\n",
    "    \n",
    "\n",
    "def retraining_batch_query(max_date):\n",
    "    query = f\"\"\"\n",
    "\n",
    "        WITH TRAIN_BASE AS (\n",
    "\n",
    "            SELECT CASE_ID,\n",
    "                   COALESCE(HOSPITAL_CODE,0) AS HOSPITAL_CODE,\n",
    "                   COALESCE(HOSPITAL_TYPE_CODE,'None') AS HOSPITAL_TYPE_CODE,\n",
    "                   COALESCE(CITY_CODE_HOSPITAL,0) AS CITY_CODE_HOSPITAL,\n",
    "                   COALESCE(HOSPITAL_REGION_CODE,'None') AS HOSPITAL_REGION_CODE,\n",
    "                   COALESCE(AVAILABLE_EXTRA_ROOMS_IN_HOSPITAL,0) AS AVAILABLE_EXTRA_ROOMS_IN_HOSPITAL,\n",
    "                   COALESCE(DEPARTMENT,'None') AS DEPARTMENT,\n",
    "                   COALESCE(WARD_TYPE,'None') AS WARD_TYPE,\n",
    "                   COALESCE(WARD_FACILITY_CODE,'None') AS WARD_FACILITY_CODE,\n",
    "                   COALESCE(BED_GRADE,0) AS BED_GRADE,\n",
    "                   PATIENTID,\n",
    "                   COALESCE(CITY_CODE_PATIENT,0) AS CITY_CODE_PATIENT,\n",
    "                   COALESCE(TYPE_OF_ADMISSION,'None') AS TYPE_OF_ADMISSION,\n",
    "                   COALESCE(SEVERITY_OF_ILLNESS,'Minor') AS SEVERITY_OF_ILLNESS,\n",
    "                   COALESCE(VISITORS_WITH_PATIENT,0) AS VISITORS_WITH_PATIENT,\n",
    "                   COALESCE(AGE,'None') AS AGE,\n",
    "                   COALESCE(ADMISSION_DEPOSIT,0) AS ADMISSION_DEPOSIT,\n",
    "                   ADMISSION_DATE,\n",
    "                   DISCHARGE_DATE\n",
    "\n",
    "            FROM HEALTHDB.HEALTHSCHEMA.HEALTH_DATA\n",
    "            WHERE ADMISSION_DATE >= '2022-11-01' --- To reduce the load\n",
    "\n",
    "        ),\n",
    "\n",
    "        TRAIN_BASE_WITH_FEATURES AS (\n",
    "\n",
    "            SELECT *,\n",
    "                    MONTHNAME(ADMISSION_DATE) AS ADMISSION_MONTH,\n",
    "                    DAYNAME(ADMISSION_DATE) AS ADMISSION_DAY,    \n",
    "                    CONCAT(TYPE_OF_ADMISSION,'-',SEVERITY_OF_ILLNESS) AS ADMISSION_ILLNESS,\n",
    "                    CONCAT(SEVERITY_OF_ILLNESS,'-',BED_GRADE) AS ILLNESS_BEDGRADE,\n",
    "                    CONCAT(DEPARTMENT,'-',SEVERITY_OF_ILLNESS) AS DEPARTMENT_ILLNESS,\n",
    "                    DATEDIFF(day,ADMISSION_DATE,DISCHARGE_DATE) AS LOS\n",
    "            FROM TRAIN_BASE \n",
    "\n",
    "        ),    \n",
    "\n",
    "        NEW_DATA_WITH_FEATURES AS (\n",
    "\n",
    "             SELECT CASE_ID,\n",
    "                       COALESCE(HOSPITAL_CODE,0) AS HOSPITAL_CODE,\n",
    "                       COALESCE(HOSPITAL_TYPE_CODE,'None') AS HOSPITAL_TYPE_CODE,\n",
    "                       COALESCE(CITY_CODE_HOSPITAL,0) AS CITY_CODE_HOSPITAL,\n",
    "                       COALESCE(HOSPITAL_REGION_CODE,'None') AS HOSPITAL_REGION_CODE,\n",
    "                       COALESCE(AVAILABLE_EXTRA_ROOMS_IN_HOSPITAL_X,0) AS AVAILABLE_EXTRA_ROOMS_IN_HOSPITAL,\n",
    "                       COALESCE(DEPARTMENT,'None') AS DEPARTMENT,\n",
    "                       COALESCE(WARD_TYPE,'None') AS WARD_TYPE,\n",
    "                       COALESCE(WARD_FACILITY_CODE,'None') AS WARD_FACILITY_CODE,\n",
    "                       COALESCE(BED_GRADE,0) AS BED_GRADE,\n",
    "                       PATIENTID,\n",
    "                       COALESCE(CITY_CODE_PATIENT,0) AS CITY_CODE_PATIENT,\n",
    "                       COALESCE(TYPE_OF_ADMISSION,'None') AS TYPE_OF_ADMISSION,\n",
    "                       COALESCE(SEVERITY_OF_ILLNESS,'Minor') AS SEVERITY_OF_ILLNESS,\n",
    "                       COALESCE(VISITORS_WITH_PATIENT_X,0) AS VISITORS_WITH_PATIENT,\n",
    "                       COALESCE(AGE,'None') AS AGE,\n",
    "                       COALESCE(ADMISSION_DEPOSIT_X,0) AS ADMISSION_DEPOSIT,\n",
    "                       ADMISSION_DATE,\n",
    "                       DISCHARGE_DATE,\n",
    "                       ADMISSION_MONTH,\n",
    "                       ADMISSION_DAY,\n",
    "                       ADMISSION_ILLNESS,\n",
    "                       ILLNESS_BEDGRADE,\n",
    "                       DEPARTMENT_ILLNESS,\n",
    "                       LOS_X AS LOS \n",
    "                    FROM HEALTHDB.HEALTHSCHEMA.TEMP_LOS_PREDICTION_MODEL_LOGGING_TABLE_HARI\n",
    "                    WHERE ADMISSION_DATE < '{max_date}'\n",
    "\n",
    "        )\n",
    "\n",
    "\n",
    "        SELECT * FROM TRAIN_BASE_WITH_FEATURES\n",
    "        UNION ALL\n",
    "        SELECT * FROM NEW_DATA_WITH_FEATURES;\n",
    "\n",
    "        \"\"\"\n",
    "    return query\n",
    "\n",
    "def retrain_model(cut_off_date):\n",
    "    with engine.connect() as conn:\n",
    "    \n",
    "        # Loading the scoring data\n",
    "        data = pd.DataFrame(pd.read_sql(retraining_batch_query(cut_off_date),conn))\n",
    "        data.columns = [col.upper() for col in data.columns.tolist()]\n",
    "        print(data.shape)\n",
    "    #     display(data.head())\n",
    "\n",
    "        # Splitting the data into Train and Test set\n",
    "        import pytz    \n",
    "        from datetime import datetime, timedelta\n",
    "        tz_NY = pytz.timezone('Asia/Kolkata')\n",
    "\n",
    "        max_date = data.ADMISSION_DATE.max()\n",
    "        min_date = max_date - timedelta(days=7)\n",
    "\n",
    "        data_train = data[(data['ADMISSION_DATE'] <= min_date)]\n",
    "        data_test = data[(data['ADMISSION_DATE'] >= min_date) & (data['ADMISSION_DATE'] <= max_date)]\n",
    "\n",
    "\n",
    "        # Applying the preprocessing steps\n",
    "        df_train_processed = LOS_Preprocessing.preprocess_data(data_train)\n",
    "        print(df_train_processed.shape)\n",
    "\n",
    "        df_test_processed = LOS_Preprocessing.preprocess_data(data_test)\n",
    "        print(df_test_processed.shape)\n",
    "\n",
    "        # Performing feature selection\n",
    "        df_final = df_train_processed.copy()\n",
    "        print(df_final.shape)\n",
    "    #     display(df_final.head())\n",
    "        print(\"Feature Selection Started..\")\n",
    "        model_feats = feature_selection(df_final)\n",
    "        print(model_feats)\n",
    "        model_feats.remove('LOS')\n",
    "\n",
    "        # Model Building\n",
    "        import xgboost as xgb\n",
    "\n",
    "        xgb_ = xgb.XGBRegressor()\n",
    "        xgb_.fit(df_final[model_feats],df_final['LOS'])\n",
    "\n",
    "        df_test_final = check_n_create_model_features(df_test_processed,model_feats)\n",
    "        if 'LOS' in df_test_final.columns.tolist():\n",
    "            df_test_final = df_test_final.drop('LOS',axis=1)\n",
    "        preds = np.ceil(xgb_.predict(df_test_final))\n",
    "        rmse = np.sqrt(metrics.mean_squared_error(df_test_processed['LOS'],preds))\n",
    "        mae = np.sqrt(metrics.mean_absolute_error(df_test_processed['LOS'],preds))\n",
    "        print(\"\\n Test Performance (new model)\")\n",
    "        print(\"RMSE: \", rmse)\n",
    "        print(\"MAE: \", mae)      \n",
    "\n",
    "        # Saving the trained model\n",
    "        booster = xgb_.get_booster()\n",
    "        booster.save_model('./Retraining Artifacts/MODEL_XGB.model')\n",
    "\n",
    "        model_xgb_metrics_new = {}\n",
    "        model_xgb_metrics_new['RMSE'] = rmse\n",
    "        model_xgb_metrics_new['MAE'] = mae\n",
    "\n",
    "        import pickle\n",
    "\n",
    "        with open('./Retraining Artifacts/MODEL_XGB_PERFM_METRICS.pkl','wb') as F:\n",
    "            pickle.dump(model_xgb_metrics_new,F)\n",
    "\n",
    "\n",
    "        # Getting the predictions from the old model\n",
    "        model = xgboost.XGBRegressor()\n",
    "        model.load_model('MODEL_XGB.model')\n",
    "    #     df_test_processed['PREDICTED_LOS'] = np.ceil(model.predict(df_test_processed[model_feats]))\n",
    "\n",
    "        with open('MODEL_FEATS.pkl','rb') as F:\n",
    "            model_feats_old = pickle.load(F)\n",
    "\n",
    "        df_test_final = check_n_create_model_features(df_test_processed,model_feats_old)\n",
    "        if 'LOS' in df_test_final.columns.tolist():\n",
    "            df_test_final = df_test_final.drop('LOS',axis=1)\n",
    "        preds = np.ceil(model.predict(df_test_final))\n",
    "        rmse = np.sqrt(metrics.mean_squared_error(df_test_processed['LOS'],preds))\n",
    "        mae = np.sqrt(metrics.mean_absolute_error(df_test_processed['LOS'],preds))\n",
    "        print(\"\\n Test Performance (old model)\")\n",
    "        print(\"RMSE: \", rmse)\n",
    "        print(\"MAE: \", mae)   \n",
    "\n",
    "        model_xgb_metrics_old = {}\n",
    "        model_xgb_metrics_old['RMSE'] = rmse\n",
    "        model_xgb_metrics_old['MAE'] = mae\n",
    "    \n",
    "    return model_xgb_metrics_new, model_xgb_metrics_old\n",
    "\n",
    "\n",
    "def finalize_model(new_perform_dict, old_perform_dict):\n",
    "    count = 0\n",
    "    for metric in new_perform_dict.keys():\n",
    "        if new_perform_dict[metric] < old_perform_dict[metric]:\n",
    "            count += 1\n",
    "    \n",
    "    if count > 0:\n",
    "        return 'New Model'\n",
    "    else:\n",
    "        return 'Old Model'\n",
    "\n",
    "    \n",
    "def deploy_model(selector='Old Model'):\n",
    "    if selector != 'Old Model':\n",
    "        # STEP-1:\n",
    "        # Loading the old model\n",
    "        with open('MODEL_FEATS.pkl','rb') as F:\n",
    "            old_feats = pickle.load(F)\n",
    "        with open('MODEL_XGB.model','rb') as F:\n",
    "            old_model = pickle.load(F)\n",
    "        with open('MODEL_XGB_PERFM_METRICS.pkl','rb') as F:\n",
    "            old_perfm_dict = pickle.load(F)\n",
    "        \n",
    "        # Saving the copy to Archive folder\n",
    "        with open('./Archive/MODEL_FEATS.pkl','wb') as F:\n",
    "            pickle.dump(old_feats,F)\n",
    "        with open('./Archive/MODEL_XGB.model','wb') as F:\n",
    "            pickle.dump(old_model,F)\n",
    "        with open('./Archive/MODEL_XGB_PERFM_METRICS.pkl','wb') as F:\n",
    "            pickle.dump(old_perfm_dict,F)\n",
    "        \n",
    "        # STEP-2:\n",
    "        # Loadin the new model\n",
    "        with open('./Retraining Artifacts/MODEL_FEATS.pkl','rb') as F:\n",
    "            new_feats = pickle.load(F)\n",
    "        with open('./Retraining Artifacts/MODEL_XGB.model','rb') as F:\n",
    "            new_model = pickle.load(F)\n",
    "        with open('./Retraining Artifacts/MODEL_XGB_PERFM_METRICS.pkl','rb') as F:\n",
    "            new_perfm_dict = pickle.load(F)\n",
    "        \n",
    "        # Replacing the old model artifacts with the new model\n",
    "        with open('MODEL_FEATS.pkl','wb') as F:\n",
    "            pickle.dump(new_feats,F)\n",
    "        with open('MODEL_XGB.model','wb') as F:\n",
    "            pickle.dump(new_model,F)\n",
    "        with open('MODEL_XGB_PERFM_METRICS.pkl','wb') as F:\n",
    "            pickle.dump(new_perfm_dict,F)\n",
    "        \n",
    "    return 'Deployment Successful'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "728ee342",
   "metadata": {},
   "source": [
    "# Retraining Trigger:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3c08a2bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data drift condition\n",
    "data_drift = data_log_df['Is Drift'].sum() > 0\n",
    "data_drift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "70159f27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model drift condition\n",
    "labels = [False, True]\n",
    "model_drift = labels[model_log_dict['Model Drift IND']]\n",
    "model_drift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "46d01329",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2022-12-25'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Max date for retraining  (cut-off date)\n",
    "cut_off_date = model_log_dict['Time Period'].split(' ')[2]\n",
    "cut_off_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3dc0a0b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retraining Started...\n",
      "(104034, 25)\n",
      "(87302, 147)\n",
      "(19020, 144)\n",
      "(87302, 147)\n",
      "Feature Selection Started..\n",
      "Final Features from both Dtree & XGB: 25\n",
      "['ADMISSION_DAY_Thu', 'CITY_CODE_HOSPITAL_7', 'ADMISSION_DEPOSIT', 'VISITORS_WITH_PATIENT', 'SEVERITY_OF_ILLNESS_Minor', 'AGE_71-80', 'CITY_CODE_PATIENT_8', 'TYPE_OF_ADMISSION_Trauma', 'ADMISSION_DAY_Fri', 'ILLNESS_BEDGRADE_Extreme-1', 'CITY_CODE_HOSPITAL_2', 'ADMISSION_MONTH_Nov', 'AVAILABLE_EXTRA_ROOMS_IN_HOSPITAL', 'ADMISSION_DAY_Tue', 'AGE_31-40', 'ILLNESS_BEDGRADE_Moderate-2', 'ADMISSION_MONTH_Dec', 'ADMISSION_DAY_Sun', 'ADMISSION_DAY_Sat', 'AGE_41-50', 'TYPE_OF_ADMISSION_Emergency', 'WARD_TYPE_S', 'WARD_TYPE_P', 'WARD_TYPE_Q', 'BED_GRADE_2', 'LOS']\n",
      "\n",
      " Test Performance (new model)\n",
      "RMSE:  15.04027890315711\n",
      "MAE:  3.3200471282429023\n",
      "\n",
      " Test Performance (old model)\n",
      "RMSE:  14.866728319837454\n",
      "MAE:  3.3015705404623406\n",
      "\n",
      "Model Selection Started...\n",
      "\n",
      "Deployment Started...\n"
     ]
    }
   ],
   "source": [
    "# Retraining trigger condition\n",
    "if data_drift == True or model_drift == True:\n",
    "    # Do retraining\n",
    "    print(\"Retraining Started...\")\n",
    "    new_dict, old_dict = retrain_model(cut_off_date)\n",
    "    \n",
    "    # Finalize the model\n",
    "    print(\"\\nModel Selection Started...\")\n",
    "    select_model = finalize_model(new_perform_dict=new_dict, old_perform_dict=old_dict)\n",
    "    \n",
    "    # Deploy the selected model\n",
    "    print(\"\\nDeployment Started...\")\n",
    "    deploy_model(select_model)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1b12cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8628fc57",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
